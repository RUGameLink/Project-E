{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Hybrid RNN Model\n",
        "This notebook contains a hybrid RNN model combining LSTM and GRU layers with Dropout and Batch Normalization."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Подключаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install chardet\n",
        "import chardet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Импорт необходимых библиотек\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, GRU, Dropout, BatchNormalization, Dense\n",
        "from keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "from keras.models import load_model\n",
        "import pickle\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Работа с набором данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка и предобработка датасета\n",
        "def load_and_preprocess_data(file_path):\n",
        "    # Открываем файл в двоичном режиме и читаем данные\n",
        "    with open(file_path, 'rb') as file:\n",
        "        raw_data = file.read()\n",
        "    # Используем chardet для определения кодировки\n",
        "    result = chardet.detect(raw_data)\n",
        "    # Получаем название кодировки\n",
        "    encoding_file = result['encoding']\n",
        "    print(f\"Кодировка файла: {encoding_file}\")\n",
        "    \n",
        "    # Загрузка данных\n",
        "    data = pd.read_csv(file_path, encoding=encoding_file, delimiter=';')\n",
        "\n",
        "    # Преобразование столбцов в соответствующие типы данных\n",
        "    data['Temperature (¡C)'] = data['Temperature (¡C)'].str.replace(',', '.').astype(float)\n",
        "    data['Pressure (mBar)'] = data['Pressure (mBar)'].str.replace(',', '.').astype(float)\n",
        "    data['Datetime'] = pd.to_datetime(data['Datetime'], format='%d.%m.%Y %H:%M')\n",
        "    data.set_index('Datetime', inplace=True)\n",
        "\n",
        "    # Заполнение пропущенных значений\n",
        "    for column in data.columns:\n",
        "        if pd.api.types.is_numeric_dtype(data[column]):\n",
        "            data[column].fillna(data[column].mean(), inplace=True)\n",
        "\n",
        "    # Разделение данных на обучающую, валидационную и тестовую выборки\n",
        "    train_data, test_data = train_test_split(data, test_size=0.1, random_state=42)\n",
        "    train_data, val_data = train_test_split(train_data, test_size=0.15, random_state=42)\n",
        "\n",
        "    # Нормализация данных\n",
        "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    train_scaled = scaler.fit_transform(train_data)\n",
        "    val_scaled = scaler.transform(val_data)\n",
        "    test_scaled = scaler.transform(test_data)\n",
        "\n",
        "    return train_scaled, val_scaled, test_scaled, scaler, test_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание датасета для RNN\n",
        "def create_rnn_dataset(dataset, time_step=1):\n",
        "    dataX, dataY = [], []\n",
        "    for i in range(len(dataset) - time_step - 1):\n",
        "        a = dataset[i:(i + time_step), :]\n",
        "        dataX.append(a)\n",
        "        dataY.append(dataset[i + time_step, 0])  # Предсказание только уровня радона\n",
        "    return np.array(dataX), np.array(dataY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Определение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Определение гибридной модели\n",
        "def create_hybrid_model(input_shape):\n",
        "    model = Sequential()\n",
        "    model.add(LSTM(32, input_shape=input_shape, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GRU(64, return_sequences=True, kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GRU(128, return_sequences=False, kernel_regularizer=l2(0.01)))\n",
        "    model.add(Dropout(0.2))\n",
        "    model.add(Dense(1, activation='linear'))\n",
        "    model.compile(optimizer='adam', loss='mse', metrics=['mae', 'mape'])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Визуализация\n",
        "### Визуализация истории обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация истории обучения\n",
        "def plot_training_history(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history.history['loss'], label='Training Loss')\n",
        "    plt.plot(history.history['val_loss'], label='Validation Loss')\n",
        "    plt.title('Потери модели по эпохам')\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация истории обучения\n",
        "def plot_mae_history(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history.history['mae'], label='MAE')\n",
        "    plt.plot(history.history['val_mae'], label='Validation MAE')\n",
        "    plt.title('Потери модели по эпохам')\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация истории обучения\n",
        "def plot_mape_history(history):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(history.history['mape'], label='MAPE')\n",
        "    plt.plot(history.history['val_mape'], label='Validation MAPE')\n",
        "    plt.title('Потери модели по эпохам')\n",
        "    plt.xlabel('Эпохи')\n",
        "    plt.ylabel('Потери')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Визуализация сравнения предсказания"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция для визуализации истинных и прогнозируемых значений\n",
        "def plot_true_vs_predicted(true_series, predicted_series):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    # Добавить строку для фактических уровней радона\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=true_series.index, \n",
        "        y=true_series, \n",
        "        mode='lines', \n",
        "        name='Actual Radon Level'\n",
        "    ))\n",
        "\n",
        "    # Добавить маркер для прогнозируемого уровня радона с hovertemplate\n",
        "    fig.add_trace(go.Scatter(\n",
        "        x=predicted_series.index, \n",
        "        y=predicted_series, \n",
        "        mode='markers', \n",
        "        name='Predicted Radon Level',\n",
        "        hovertemplate=(\n",
        "            'Date: %{x|%Y-%m-%d %H:%M:%S}<br>' +\n",
        "            'Predicted: %{y:.2f}<br>' +\n",
        "            'Actual: %{customdata:.2f}<br>' +\n",
        "            'Actual Date: %{x|%Y-%m-%d %H:%M:%S}<extra></extra>'\n",
        "        ),\n",
        "        customdata=true_series\n",
        "    ))\n",
        "\n",
        "    # Добавить заголовок и метки осей\n",
        "    fig.update_layout(\n",
        "        title='Predicted vs Actual Radon Level', \n",
        "        xaxis_title='Datetime', \n",
        "        yaxis_title='Radon (Bq.m3)'\n",
        "    )\n",
        "\n",
        "    fig.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сохранение модели и истории обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение обученной модели\n",
        "def save_model(model, model_path):\n",
        "    \"\"\"\n",
        "    Сохраняет обученную модель на диск.\n",
        "    \n",
        "    :param model: Обученная модель Keras\n",
        "    :param model_path: Путь для сохранения модели\n",
        "    \"\"\"\n",
        "    model.save(model_path)\n",
        "    print(f\"Модель сохранена в {model_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение истории обучения\n",
        "def save_training_history(history, history_path):\n",
        "    \"\"\"\n",
        "    Сохраняет историю обучения модели в файл.\n",
        "    \n",
        "    :param history: Объект истории обучения, возвращаемый model.fit()\n",
        "    :param history_path: Путь для сохранения истории\n",
        "    \"\"\"\n",
        "    with open(history_path, 'wb') as file_pi:\n",
        "        pickle.dump(history.history, file_pi)\n",
        "    print(f\"История обучения сохранена в {history_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Работа модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "file_path = '/content/data.csv'  # Путь к файлу с данными\n",
        "train_scaled, val_scaled, test_scaled, scaler, test_data = load_and_preprocess_data(file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "time_step = 168\n",
        "X_train, y_train = create_rnn_dataset(train_scaled, time_step)\n",
        "X_val, y_val = create_rnn_dataset(val_scaled, time_step)\n",
        "X_test, y_test = create_rnn_dataset(test_scaled, time_step)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Изменение формы входных данных\n",
        "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], train_scaled.shape[1])\n",
        "X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], val_scaled.shape[1])\n",
        "X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], test_scaled.shape[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Создание и обучение модели\n",
        "model = create_hybrid_model((X_train.shape[1], X_train.shape[2]))\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=20, batch_size=16, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация истории обучения\n",
        "plot_training_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mae_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plot_mape_history(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluate the model\n",
        "test_loss, test_mae, test_mape = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test Loss: {test_loss}, Test MAE: {test_mae}, Test MAPE: {test_mape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Оценка модели\n",
        "test_loss, test_mae, test_mape = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Потери на тесте: {test_loss}, MAE на тесте: {test_mae}, MAPE на тесте: {test_mape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Получение предсказаний модели на тестовых данных\n",
        "test_predictions = model.predict(X_test)\n",
        "\n",
        "# Инвертирование масштабирования для получения реальных значений\n",
        "def invert_scaling(scaled_value, scaler, column_index=0):\n",
        "    # Создаем пустой массив размерности исходных данных\n",
        "    dummy = np.zeros((len(scaled_value), scaler.scale_.shape[0]))\n",
        "    # Заполняем столбец с целевой переменной масштабированными значениями\n",
        "    dummy[:, column_index] = scaled_value\n",
        "    # Инвертируем масштабирование\n",
        "    return scaler.inverse_transform(dummy)[:, column_index]\n",
        "\n",
        "# Инвертируем масштабирование для истинных и предсказанных значений\n",
        "y_test_inv = invert_scaling(y_test, scaler)\n",
        "test_pred_inv = invert_scaling(test_predictions.flatten(), scaler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация фактических vs предсказанных значений\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.plot(y_test_inv, label='Фактические значения')\n",
        "plt.plot(test_pred_inv, label='Предсказанные значения')\n",
        "plt.title('Сравнение фактических и предсказанных значений радона')\n",
        "plt.xlabel('Временной шаг')\n",
        "plt.ylabel('Radon (Bq.m3)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# График рассеяния для проверки корреляции между фактическими и предсказанными значениями\n",
        "from scipy import stats\n",
        "import matplotlib.patches as mpatches\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# Добавляем градиентную окраску точек по плотности для лучшей визуализации\n",
        "from scipy.stats import gaussian_kde\n",
        "xy = np.vstack([y_test_inv, test_pred_inv])\n",
        "z = gaussian_kde(xy)(xy)\n",
        "idx = z.argsort()\n",
        "x, y, z = y_test_inv[idx], test_pred_inv[idx], z[idx]\n",
        "\n",
        "# Создаем основной график рассеяния с градиентной окраской\n",
        "scatter = plt.scatter(x, y, c=z, s=50, alpha=0.6, cmap='viridis', edgecolor='w', linewidth=0.5)\n",
        "\n",
        "# Линия идеальной корреляции\n",
        "ideal_line, = plt.plot([y_test_inv.min(), y_test_inv.max()], \n",
        "                      [y_test_inv.min(), y_test_inv.max()], \n",
        "                      'r--', linewidth=2, label='Идеальная корреляция (y=x)')\n",
        "\n",
        "# Добавляем линию регрессии\n",
        "slope, intercept, r_value, p_value, std_err = stats.linregress(y_test_inv, test_pred_inv)\n",
        "regression_line, = plt.plot(\n",
        "    [y_test_inv.min(), y_test_inv.max()], \n",
        "    [slope*y_test_inv.min() + intercept, slope*y_test_inv.max() + intercept], \n",
        "    'b-', linewidth=2, \n",
        "    label=f'Линия регрессии (y={slope:.4f}x+{intercept:.2f})'\n",
        ")\n",
        "\n",
        "# Добавляем цветовую шкалу\n",
        "cbar = plt.colorbar(scatter)\n",
        "cbar.set_label('Плотность точек', rotation=270, labelpad=20, fontsize=12)\n",
        "\n",
        "# Добавляем статистическую информацию\n",
        "r_squared = r_value**2\n",
        "mae = np.mean(np.abs(y_test_inv - test_pred_inv))\n",
        "rmse = np.sqrt(np.mean((y_test_inv - test_pred_inv)**2))\n",
        "\n",
        "stats_text = f\"\"\"\n",
        "Статистические показатели:\n",
        "R² = {r_squared:.4f}\n",
        "Коэффициент корреляции = {r_value:.4f}\n",
        "MAE = {mae:.2f}\n",
        "RMSE = {rmse:.2f}\n",
        "\"\"\"\n",
        "\n",
        "plt.annotate(stats_text, xy=(0.02, 0.95), xycoords='axes fraction', \n",
        "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8),\n",
        "             fontsize=12, verticalalignment='top')\n",
        "\n",
        "# Добавляем примечания по интерпретации\n",
        "interpretation_text = \"\"\"\n",
        "Интерпретация:\n",
        "• Точки вдоль красной линии: точные предсказания\n",
        "• Точки выше линии: переоценка модели\n",
        "• Точки ниже линии: недооценка модели\n",
        "• R² ближе к 1.0 означает лучшую предсказательную способность\n",
        "\"\"\"\n",
        "\n",
        "plt.annotate(interpretation_text, xy=(0.02, 0.78), xycoords='axes fraction', \n",
        "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8),\n",
        "             fontsize=12, verticalalignment='top')\n",
        "\n",
        "# Выделяем области переоценки и недооценки\n",
        "overestimation = mpatches.Patch(color='lightblue', alpha=0.3, label='Область переоценки')\n",
        "underestimation = mpatches.Patch(color='lightcoral', alpha=0.3, label='Область недооценки')\n",
        "\n",
        "# Добавляем полупрозрачные области для визуализации переоценки/недооценки\n",
        "plt.fill_between([y_test_inv.min(), y_test_inv.max()], \n",
        "                 [y_test_inv.min(), y_test_inv.max()], \n",
        "                 [y_test_inv.max()*2, y_test_inv.max()*2], \n",
        "                 color='lightblue', alpha=0.1)\n",
        "plt.fill_between([y_test_inv.min(), y_test_inv.max()], \n",
        "                 [y_test_inv.min(), y_test_inv.max()], \n",
        "                 [y_test_inv.min()*-0.5, y_test_inv.min()*-0.5], \n",
        "                 color='lightcoral', alpha=0.1)\n",
        "\n",
        "# Создаем легенду с добавленными элементами\n",
        "plt.legend(handles=[ideal_line, regression_line, overestimation, underestimation], \n",
        "           loc='lower right', fontsize=12)\n",
        "\n",
        "# Добавляем названия осей и заголовок\n",
        "plt.title('Корреляция между фактическими и предсказанными значениями радона', fontsize=16)\n",
        "plt.xlabel('Фактические значения (Bq.m3)', fontsize=14)\n",
        "plt.ylabel('Предсказанные значения (Bq.m3)', fontsize=14)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Устанавливаем одинаковый масштаб для осей\n",
        "plt.axis('equal')\n",
        "plt.tight_layout()\n",
        "\n",
        "# Добавляем информацию о диапазоне значений\n",
        "range_text = f\"Диапазон фактических значений: [{y_test_inv.min():.2f}, {y_test_inv.max():.2f}]\"\n",
        "plt.annotate(range_text, xy=(0.02, 0.02), xycoords='axes fraction', \n",
        "             fontsize=12, verticalalignment='bottom')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Дополнительно выводим процент точек в пределах определенной погрешности\n",
        "rel_error_10 = np.sum(np.abs((y_test_inv - test_pred_inv) / y_test_inv) <= 0.1) / len(y_test_inv) * 100\n",
        "rel_error_20 = np.sum(np.abs((y_test_inv - test_pred_inv) / y_test_inv) <= 0.2) / len(y_test_inv) * 100\n",
        "rel_error_30 = np.sum(np.abs((y_test_inv - test_pred_inv) / y_test_inv) <= 0.3) / len(y_test_inv) * 100\n",
        "\n",
        "print(f\"Процент предсказаний с относительной ошибкой ≤10%: {rel_error_10:.2f}%\")\n",
        "print(f\"Процент предсказаний с относительной ошибкой ≤20%: {rel_error_20:.2f}%\")\n",
        "print(f\"Процент предсказаний с относительной ошибкой ≤30%: {rel_error_30:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Гистограмма распределения ошибок\n",
        "errors = y_test_inv - test_pred_inv\n",
        "mean_error = np.mean(errors)\n",
        "std_error = np.std(errors)\n",
        "\n",
        "plt.figure(figsize=(12, 7))\n",
        "\n",
        "# Создаем гистограмму с большим количеством бинов для детализации\n",
        "n, bins, patches = plt.hist(errors, bins=50, alpha=0.75, color='skyblue', \n",
        "                           edgecolor='black', label='Распределение ошибок')\n",
        "\n",
        "# Добавляем вертикальные линии для ключевых статистик\n",
        "plt.axvline(x=0, color='r', linestyle='--', linewidth=2, \n",
        "           label='Идеальное предсказание (ошибка = 0)')\n",
        "plt.axvline(x=mean_error, color='green', linestyle='-', linewidth=2,\n",
        "           label=f'Среднее значение ошибки: {mean_error:.2f}')\n",
        "plt.axvline(x=mean_error + std_error, color='orange', linestyle='-.', linewidth=1.5,\n",
        "           label=f'+1 станд. отклонение: {(mean_error + std_error):.2f}')\n",
        "plt.axvline(x=mean_error - std_error, color='orange', linestyle='-.', linewidth=1.5,\n",
        "           label=f'-1 станд. отклонение: {(mean_error - std_error):.2f}')\n",
        "\n",
        "# Подсвечиваем область в пределах одного стандартного отклонения\n",
        "plt.axvspan(mean_error - std_error, mean_error + std_error, alpha=0.2, color='yellow', \n",
        "           label='Диапазон ±1σ (68% ошибок)')\n",
        "\n",
        "# Добавляем статистические аннотации\n",
        "stat_text = f\"\"\"\n",
        "Статистика ошибок:\n",
        "Мин: {errors.min():.2f}\n",
        "Макс: {errors.max():.2f}\n",
        "Среднее: {mean_error:.2f}\n",
        "Медиана: {np.median(errors):.2f}\n",
        "Станд. отклонение: {std_error:.2f}\n",
        "\"\"\"\n",
        "plt.annotate(stat_text, xy=(0.02, 0.75), xycoords='axes fraction', \n",
        "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8))\n",
        "\n",
        "# Добавляем информацию о нормальности распределения\n",
        "from scipy import stats\n",
        "_, p_value = stats.normaltest(errors)\n",
        "normality_text = f\"Тест на нормальность (D'Agostino-Pearson):\\np-value: {p_value:.4f}\"\n",
        "if p_value < 0.05:\n",
        "    normality_text += \"\\nРаспределение не является нормальным\"\n",
        "else:\n",
        "    normality_text += \"\\nРаспределение близко к нормальному\"\n",
        "    \n",
        "plt.annotate(normality_text, xy=(0.02, 0.60), xycoords='axes fraction',\n",
        "             bbox=dict(boxstyle=\"round,pad=0.5\", facecolor='white', alpha=0.8))\n",
        "\n",
        "# Улучшаем оформление графика\n",
        "plt.title('Распределение ошибок модели предсказания радона', fontsize=14)\n",
        "plt.xlabel('Ошибка (Bq.m3)', fontsize=12)\n",
        "plt.ylabel('Частота', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Добавляем легенду\n",
        "plt.legend(loc='upper right', fontsize=10)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Дополнительно выводим процент ошибок, попадающих в разные диапазоны\n",
        "within_1std = np.sum((errors >= mean_error - std_error) & (errors <= mean_error + std_error)) / len(errors) * 100\n",
        "within_2std = np.sum((errors >= mean_error - 2*std_error) & (errors <= mean_error + 2*std_error)) / len(errors) * 100\n",
        "within_3std = np.sum((errors >= mean_error - 3*std_error) & (errors <= mean_error + 3*std_error)) / len(errors) * 100\n",
        "\n",
        "print(f\"Процент ошибок в пределах ±1σ: {within_1std:.2f}%\")\n",
        "print(f\"Процент ошибок в пределах ±2σ: {within_2std:.2f}%\")\n",
        "print(f\"Процент ошибок в пределах ±3σ: {within_3std:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# График остатков\n",
        "plt.figure(figsize=(12, 6))\n",
        "scatter = plt.scatter(y_test_inv, errors, alpha=0.5, c=errors, cmap='coolwarm')\n",
        "plt.axhline(y=0, color='r', linestyle='--', label='Ошибка = 0')\n",
        "plt.colorbar(scatter, label='Величина ошибки (Bq.m3)')\n",
        "\n",
        "# Добавляем область для выделения допустимых ошибок (±1000 Bq.m3)\n",
        "plt.axhspan(-1000, 1000, alpha=0.2, color='green', label='Допустимый диапазон (±1000 Bq.m3)')\n",
        "\n",
        "plt.title('График остатков модели предсказания радона', fontsize=14)\n",
        "plt.xlabel('Фактические значения (Bq.m3)', fontsize=12)\n",
        "plt.ylabel('Остатки (Bq.m3)', fontsize=12)\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "# Добавляем текст с пояснениями\n",
        "plt.annotate('Положительные остатки: модель недооценивает', \n",
        "             xy=(0.05, 0.85), xycoords='axes fraction', fontsize=10)\n",
        "plt.annotate('Отрицательные остатки: модель переоценивает', \n",
        "             xy=(0.05, 0.15), xycoords='axes fraction', fontsize=10)\n",
        "\n",
        "# Отображаем среднее значение ошибки\n",
        "mean_error = np.mean(errors)\n",
        "plt.axhline(y=mean_error, color='blue', linestyle='-', \n",
        "            label=f'Среднее значение ошибки: {mean_error:.2f}')\n",
        "\n",
        "# Добавляем легенду\n",
        "plt.legend(loc='best', fontsize=10)\n",
        "\n",
        "# Улучшаем внешний вид\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Визуализация временного ряда с доверительным интервалом\n",
        "plt.figure(figsize=(14, 7))\n",
        "# Выборка из 100 точек для лучшей визуализации\n",
        "sample = slice(0, 100)\n",
        "plt.plot(y_test_inv[sample], 'b-', label='Фактические значения')\n",
        "plt.plot(test_pred_inv[sample], 'r--', label='Предсказанные значения')\n",
        "# Доверительный интервал (условно ±1 стандартное отклонение ошибок)\n",
        "std_error = np.std(errors)\n",
        "plt.fill_between(\n",
        "    range(100),\n",
        "    test_pred_inv[sample] - std_error,\n",
        "    test_pred_inv[sample] + std_error,\n",
        "    color='gray', alpha=0.2, label='Доверительный интервал'\n",
        ")\n",
        "plt.title('Временной ряд с доверительным интервалом')\n",
        "plt.xlabel('Временной шаг')\n",
        "plt.ylabel('Radon (Bq.m3)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Предполагается, что model, X_test, y_test, и scaler уже определены\n",
        "# Получение предсказаний модели на тестовых данных\n",
        "predicted_values = model.predict(X_test)\n",
        "\n",
        "# Создание массива с той же формой, что и исходные данные\n",
        "# Заполнение предсказанными значениями только первого столбца (уровень радона)\n",
        "predicted_values_full = np.zeros((predicted_values.shape[0], X_test.shape[2]))\n",
        "predicted_values_full[:, 0] = predicted_values[:, 0]\n",
        "\n",
        "# Обратное преобразование предсказанных значений из нормализованных данных\n",
        "predicted_values_full = scaler.inverse_transform(predicted_values_full)\n",
        "\n",
        "# Извлечение только предсказанных значений уровня радона\n",
        "predicted_radon_values = predicted_values_full[:, 0]\n",
        "\n",
        "# Обратное преобразование истинных значений из нормализованных данных\n",
        "true_values_full = np.zeros((y_test.shape[0], X_test.shape[2]))\n",
        "true_values_full[:, 0] = y_test\n",
        "true_values_full = scaler.inverse_transform(true_values_full)\n",
        "true_radon_values = true_values_full[:, 0]\n",
        "\n",
        "# Предполагается, что test_data - это ваш DataFrame с тестовыми данными и индексом времени\n",
        "# Убедитесь, что test_data содержит правильный индекс времени\n",
        "true_radon_series = pd.Series(true_radon_values, index=test_data.index[-len(true_radon_values):])\n",
        "predicted_radon_series = pd.Series(predicted_radon_values, index=test_data.index[-len(predicted_radon_values):])\n",
        "\n",
        "# Сортировка данных по индексу\n",
        "true_radon_series_sorted = true_radon_series.sort_index()\n",
        "predicted_radon_series_sorted = predicted_radon_series.sort_index()\n",
        "\n",
        "# Пример использования\n",
        "plot_true_vs_predicted(true_radon_series_sorted, predicted_radon_series_sorted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = '/content/hybrid_model.h5'  # Путь для сохранения модели\n",
        "history_path = '/content/training_history.pkl'  # Путь для сохранения истории обучения"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение модели и истории\n",
        "save_model(model, model_path)\n",
        "save_training_history(history, history_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Загрузка модели (при необходимости)\n",
        "# model = load_model(model_path)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
